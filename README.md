# Prompt-Engineer-Assessment


## ğŸ“‹ Overview

This project showcases advanced prompt engineering capabilities across five comprehensive tasks, demonstrating expertise in AI content humanization, structured prompt systems, multi-modal content generation, and system optimization.

### ğŸ¯ Key Features

- **ğŸ¤– AI Content Humanization** - Advanced techniques to bypass AI detection
- **ğŸ™ï¸ Podcast Prompt Systems** - Structured, API-ready content generation
- **ğŸ¨ Visual Brand Consistency** - Cohesive image generation prompts
- **ğŸ¬ Video Prompt Engineering** - Structured video content systems
- **ğŸ” System Audit & Optimization** - Critical analysis and redesign of existing AI systems

## ğŸ—ï¸ Architecture

\`\`\`
prompt-engineer-assessment/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ main.py                 # Main orchestrator
â”‚   â”œâ”€â”€ config.py              # Configuration & client setup
â”‚   â”œâ”€â”€ task1_humanization.py  # AI content humanization
â”‚   â”œâ”€â”€ task2_podcast.py       # Podcast prompt systems
â”‚   â”œâ”€â”€ task3a_images.py       # Image generation prompts
â”‚   â”œâ”€â”€ task3b_video.py        # Video prompt frameworks
â”‚   â””â”€â”€ task4_audit.py         # System audit & redesign
â”œâ”€â”€ ğŸ“ outputs/                # Generated content & results
â”œâ”€â”€ ğŸ“ docs/                   # Documentation & examples
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env.example              # Environment template
â””â”€â”€ README.md                 # This file
\`\`\`

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Azure OpenAI API access
- Git

### Installation

1. **Clone the repository**
   \`\`\`bash
   git clone https://github.com/Sureshsharmah/Prompt-Systems-Assessment
   cd prompt-engineer-assessment
   \`\`\`

2. **Create virtual environment**
   \`\`\`bash
   python -m venv venv
   
   # Windows
   venv\Scripts\activate

3. **Install dependencies**
   \`\`\`bash
   pip install -r requirements.txt
   \`\`\`

4. **Environment setup**
   \`\`\`bash
   # Copy environment template
   cp .env.example .env
   
   # Edit .env with your Azure OpenAI credentials
   # AZURE_OPENAI_API_KEY=your_key_here
   # AZURE_OPENAI_ENDPOINT=your_endpoint_here
   \`\`\`

5. **Run the assessment**
   \`\`\`bash
   python main.py
   \`\`\`

## ğŸ”§ Configuration

Create a `.env` file with your Azure OpenAI credentials:

\`\`\`env
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource.cognitiveservices.azure.com
AZURE_OPENAI_API_VERSION=2024-06-01
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
\`\`\`

## ğŸ“Š Tasks Overview

### Task 1: AI Content Humanization ğŸ¤–â¡ï¸ğŸ‘¤
- **Objective**: Transform AI-generated content to pass detection systems
- **Techniques**: Natural language patterns, personal anecdotes, varied structures
- **Output**: Human-like articles that maintain factual accuracy

### Task 2: Podcast Prompt Engineering ğŸ™ï¸
- **Objective**: Create structured, repeatable podcast generation system
- **Format**: Cold Open â†’ Intro â†’ 3 Segments â†’ CTA
- **Focus**: Consistency across multiple episodes via API

### Task 3a: Visual Brand Consistency ğŸ¨
- **Objective**: Generate cohesive image series with brand guidelines
- **Style**: Grayscale + teal accent (#30C9CB)
- **Challenge**: Maintain consistency across multiple generations

### Task 3b: Video Prompt Systems ğŸ¬
- **Objective**: Structure prompts for 15-20 second video content
- **Platform**: Runway ML / Pika Labs compatible
- **Focus**: Scene transitions, pacing, visual coherence

### Task 4: System Audit & Redesign ğŸ”
- **Objective**: Analyze and improve existing GPT systems
- **Approach**: Identify failure points, redesign architecture
- **Outcome**: Multi-stage prompt system with validation

## ğŸ“ˆ Results & Outputs

After running the assessment, you'll find:

\`\`\`
Prompt_Engineer_Test/
â”œâ”€â”€ Task_1_Humanization/
â”‚   â”œâ”€â”€ Original_Article.txt      # AI-generated baseline
â”‚   â”œâ”€â”€ Humanized_Version.txt     # Human-like rewrite
â”‚   â”œâ”€â”€ Detection_Results.json    # Analysis metrics
â”‚   â””â”€â”€ Notes.md                  # Methodology explanation
â”œâ”€â”€ Task_2_Podcast_Prompts/
â”‚   â”œâ”€â”€ Prompt_System.json        # Structured prompt framework
â”‚   â”œâ”€â”€ Sample_Output.json        # Generated episode content
â”‚   â””â”€â”€ Notes.md                  # Scaling strategies
â”œâ”€â”€ Task_3a_Image_Generation/
â”‚   â”œâ”€â”€ Prompts.json              # Image generation prompts
â”‚   â”œâ”€â”€ Image_*.png               # Generated images (if available)
â”‚   â””â”€â”€ Notes.md                  # Brand consistency guide
â”œâ”€â”€ Task_3b_Video_Generation/
â”‚   â”œâ”€â”€ Prompt_System.json        # Video prompt structure
â”‚   â”œâ”€â”€ Runway_Prompts.json       # Platform-specific prompts
â”‚   â””â”€â”€ Notes.md                  # Production guidelines
â””â”€â”€ Task_4_Prompt_Audit/
    â”œâ”€â”€ Original_Review.json      # System analysis
    â”œâ”€â”€ Redesigned_System.json    # Improved architecture
    â””â”€â”€ Sample_Comparison.json    # Before/after comparison
\`\`\`

## ğŸ› ï¸ Technical Highlights

### Production-Ready Features
- âœ… **Robust error handling** with graceful fallbacks
- âœ… **Modular architecture** for easy maintenance
- âœ… **Comprehensive logging** for debugging
- âœ… **Environment-based configuration**
- âœ… **Professional code organization**

### AI Integration
- âœ… **Azure OpenAI API** integration
- âœ… **Multi-model support** (GPT-4o, DALL-E-3)
- âœ… **Rate limiting** and retry logic
- âœ… **Cost optimization** strategies

## ğŸ¯ Key Achievements

| Task | Status | Highlights |
|------|--------|------------|
| Humanization | âœ… Complete | human-like content, passes AI detection |
| Podcast System | âœ… Complete | Structured 6-minute episodes, consistent tone |
| Image Prompts | âœ… Complete | Brand-consistent visual series |
| Video Framework | âœ… Complete | Production-ready video prompt system |
| System Audit | âœ… Complete | 4-stage improvement over original GPT |

## ğŸ” Code Quality

- **Type hints** for better code documentation
- **Error handling** for production reliability
- **Modular design** for scalability
- **Clean architecture** following SOLID principles
- **Comprehensive documentation**

## ğŸš€ Running Individual Tasks

\`\`\`bash
# Run specific task
python -c "from task1_humanization import HumanizationTask; HumanizationTask('output').execute()"

# Test Azure connection
python -c "from config import get_azure_openai_client; print('âœ… Connected!' if get_azure_openai_client() else 'âŒ Failed')"

# Generate sample content
python main.py --task 1  # Run only Task 1
\`\`\`

## ğŸ“š Documentation

- [Task 1: Humanization Guide](docs/task1-humanization.md)
- [Task 2: Podcast Systems](docs/task2-podcast.md)
- [Task 3: Visual Content](docs/task3-visual.md)
- [Task 4: System Optimization](docs/task4-audit.md)

## ğŸ¤ Contributing

This is a screening test submission, but feedback and suggestions are welcome!

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request


## ğŸ‘¨â€ğŸ’» Author

**Suresh Sharma**
- ğŸ’¼ LinkedIn: https://www.linkedin.com/in/suresh-sharma-90942b231/
- ğŸ“§ Email: ssharma02028@gmail.com


**Built with â¤ï¸ for the Prompt Engineer role at Perssonify**

[â­ Star this repo](https://github.com/Sureshsharmah/Prompt-Systems-Assessment) if you found it helpful!


